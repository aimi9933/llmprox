# IDE Python Proxy Server API æ–‡æ¡£

## æ¦‚è¿°

IDE Python Proxy Server æ˜¯ä¸€ä¸ªæ™ºèƒ½çš„ä»£ç†æœåŠ¡å™¨ï¼Œä¸ºIDEæä¾›ä»£ç è¡¥å…¨ã€è°ƒè¯•åˆ†æå’Œå¯¹è¯è®°å¿†åŠŸèƒ½ã€‚é€šè¿‡è¯­ä¹‰åˆ†å—å’Œæœ¬åœ°LLMé›†æˆï¼Œå®ç°æ™ºèƒ½çš„ä»£ç ä¸Šä¸‹æ–‡ç®¡ç†ã€‚

## æ ¸å¿ƒåŠŸèƒ½

- ğŸ” **æ™ºèƒ½è¯­ä¹‰åˆ†å—**: åŸºäºä»£ç è¯­ä¹‰çš„æ™ºèƒ½åˆ†å—ç®—æ³•
- ğŸ§  **å¯¹è¯è®°å¿†ç®¡ç†**: ç»´æŠ¤ä¸Šä¸‹æ–‡ç›¸å…³çš„å¯¹è¯å†å²
- âš¡ **é«˜æ€§èƒ½API**: åŸºäºFastAPIçš„å¼‚æ­¥APIæœåŠ¡
- ğŸ”— **æœ¬åœ°LLMé›†æˆ**: æ”¯æŒOllamaã€LM Studioç­‰æœ¬åœ°LLM
- ğŸ“ **ä»£ç è¡¥å…¨**: æ™ºèƒ½ä»£ç è¡¥å…¨å’Œå»ºè®®
- ğŸ› **è°ƒè¯•è¾…åŠ©**: ä»£ç é”™è¯¯åˆ†æå’Œä¿®å¤å»ºè®®

## API åŸºç¡€ä¿¡æ¯

- **åŸºç¡€URL**: `http://localhost:8000`
- **APIç‰ˆæœ¬**: `v1`
- **è®¤è¯**: ç›®å‰ä¸éœ€è¦è®¤è¯ï¼ˆç”Ÿäº§ç¯å¢ƒå»ºè®®æ·»åŠ ï¼‰

## API ç«¯ç‚¹

### 1. å¥åº·æ£€æŸ¥å’Œé…ç½®

#### GET `/health/`
å¥åº·æ£€æŸ¥æ¥å£

**å“åº”ç¤ºä¾‹**:
```json
{
  "status": "healthy",
  "version": "1.0.0",
  "llm_provider": "ollama",
  "llm_status": "connected",
  "timestamp": "2024-01-01T00:00:00Z"
}
```

#### GET `/health/models`
è·å–å¯ç”¨çš„LLMæ¨¡å‹åˆ—è¡¨

**å“åº”ç¤ºä¾‹**:
```json
{
  "provider": "ollama",
  "models": ["codellama", "llama2", "mistral"],
  "default_model": "codellama"
}
```

#### GET `/health/config`
è·å–æœåŠ¡é…ç½®ä¿¡æ¯

**å“åº”ç¤ºä¾‹**:
```json
{
  "api_version": "1.0.0",
  "llm_provider": "ollama",
  "default_model": "codellama",
  "max_context_length": 8000,
  "max_chunk_size": 2000,
  "similarity_threshold": 0.7,
  "supported_extensions": [".py", ".js", ".ts", ".java"]
}
```

### 2. ä»£ç åˆ†æ

#### POST `/code/context`
åˆ†æä»£ç å¹¶è¿”å›è¯­ä¹‰åˆ†å—

**è¯·æ±‚ä½“**:
```json
{
  "code": "def hello():\n    print('Hello')",
  "file_path": "test.py",
  "language": "python",
  "max_chunks": 5
}
```

**å“åº”ç¤ºä¾‹**:
```json
{
  "chunks": [
    {
      "id": "abc123",
      "content": "def hello():\n    print('Hello')",
      "file_path": "test.py",
      "start_line": 1,
      "end_line": 2,
      "language": "python",
      "token_count": 10,
      "metadata": {
        "line_count": 2,
        "char_count": 25
      }
    }
  ],
  "total_tokens": 10,
  "processing_time_ms": 15.5
}
```

#### POST `/code/complete`
ä»£ç è¡¥å…¨

**è¯·æ±‚ä½“**:
```json
{
  "code": "def calculate_sum(a, b):\n    ",
  "file_path": "utils.py",
  "cursor_position": 28,
  "language": "python",
  "context_window": 4000,
  "session_id": "optional-session-id",
  "max_tokens": 256,
  "temperature": 0.7
}
```

**å“åº”ç¤ºä¾‹**:
```json
{
  "suggestions": [
    "return a + b",
    "result = a + b\n    return result",
    "total = a + b\n    return total"
  ],
  "confidence_scores": [0.9, 0.8, 0.7],
  "context_chunks": [...],
  "session_id": "session-123",
  "response_time_ms": 250.5
}
```

#### POST `/code/debug`
ä»£ç è°ƒè¯•åˆ†æ

**è¯·æ±‚ä½“**:
```json
{
  "code": "def divide(a, b):\n    return a / b",
  "file_path": "math.py",
  "error_message": "ZeroDivisionError: division by zero",
  "language": "python",
  "session_id": "optional-session-id"
}
```

**å“åº”ç¤ºä¾‹**:
```json
{
  "analysis": "å‡½æ•°æ²¡æœ‰å¤„ç†é™¤é›¶é”™è¯¯çš„æƒ…å†µ...",
  "suggestions": [
    "æ·»åŠ é™¤é›¶æ£€æŸ¥",
    "ä½¿ç”¨try-exceptå¤„ç†å¼‚å¸¸",
    "æ·»åŠ å‚æ•°éªŒè¯"
  ],
  "fixed_code": "def divide(a, b):\n    if b == 0:\n        raise ValueError('é™¤æ•°ä¸èƒ½ä¸ºé›¶')\n    return a / b",
  "context_chunks": [...],
  "session_id": "session-123",
  "response_time_ms": 450.2
}
```

### 3. èŠå¤©å¯¹è¯

#### POST `/chat/message`
å‘é€èŠå¤©æ¶ˆæ¯

**è¯·æ±‚ä½“**:
```json
{
  "message": "å¦‚ä½•ä¼˜åŒ–è¿™ä¸ªå‡½æ•°çš„æ€§èƒ½ï¼Ÿ",
  "session_id": "optional-session-id",
  "context_code": "def slow_function():\n    # ä»£ç å†…å®¹",
  "file_path": "utils.py",
  "language": "python"
}
```

**å“åº”ç¤ºä¾‹**:
```json
{
  "response": "è¿™ä¸ªå‡½æ•°å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼ä¼˜åŒ–...",
  "session_id": "session-123",
  "context_chunks": [...],
  "response_time_ms": 320.1
}
```

#### GET `/chat/history/{session_id}`
è·å–èŠå¤©å†å²

**å“åº”ç¤ºä¾‹**:
```json
{
  "messages": [
    {
      "id": "msg-1",
      "role": "user",
      "content": "å¦‚ä½•ä¼˜åŒ–è¿™ä¸ªå‡½æ•°ï¼Ÿ",
      "timestamp": "2024-01-01T12:00:00Z",
      "context_chunks": ["chunk-1", "chunk-2"]
    },
    {
      "id": "msg-2",
      "role": "assistant",
      "content": "ä½ å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼ä¼˜åŒ–...",
      "timestamp": "2024-01-01T12:00:05Z",
      "context_chunks": ["chunk-1", "chunk-2"]
    }
  ],
  "session_id": "session-123",
  "total_messages": 2
}
```

#### GET `/chat/sessions`
åˆ—å‡ºæ‰€æœ‰ä¼šè¯

**å“åº”ç¤ºä¾‹**:
```json
{
  "sessions": [
    {
      "session_id": "session-123",
      "message_count": 5,
      "last_activity": "2024-01-01T12:30:00Z",
      "roles": ["user", "assistant"]
    }
  ]
}
```

#### DELETE `/chat/session/{session_id}`
æ¸…é™¤ä¼šè¯

**å“åº”ç¤ºä¾‹**:
```json
{
  "message": "Session cleared",
  "session_id": "session-123"
}
```

## é…ç½®é€‰é¡¹

æœåŠ¡å™¨å¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡æˆ–`.env`æ–‡ä»¶é…ç½®ï¼š

```bash
# APIè®¾ç½®
API_HOST=0.0.0.0
API_PORT=8000

# LLMè®¾ç½®
LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434
DEFAULT_MODEL=codellama

# ä¸Šä¸‹æ–‡ç®¡ç†
MAX_CONTEXT_LENGTH=8000
CHUNK_OVERLAP_RATIO=0.1
MAX_CHUNK_SIZE=2000

# è¯­ä¹‰åˆ†å—
EMBEDDING_MODEL=all-MiniLM-L6-v2
SIMILARITY_THRESHOLD=0.7

# å¯¹è¯è®°å¿†
MAX_DIALOG_HISTORY=20
MEMORY_TTL=3600
```

## é”™è¯¯å¤„ç†

APIä½¿ç”¨æ ‡å‡†HTTPçŠ¶æ€ç ï¼š

- `200`: æˆåŠŸ
- `400`: è¯·æ±‚å‚æ•°é”™è¯¯
- `500`: æœåŠ¡å™¨å†…éƒ¨é”™è¯¯
- `503`: æœåŠ¡ä¸å¯ç”¨ï¼ˆå¦‚LLMæœåŠ¡æœªå¯åŠ¨ï¼‰

é”™è¯¯å“åº”æ ¼å¼ï¼š
```json
{
  "detail": "é”™è¯¯æè¿°ä¿¡æ¯"
}
```

## ä½¿ç”¨ç¤ºä¾‹

### Pythonå®¢æˆ·ç«¯ç¤ºä¾‹

```python
import requests

# ä»£ç è¡¥å…¨
response = requests.post("http://localhost:8000/code/complete", json={
    "code": "def hello():\n    ",
    "file_path": "test.py",
    "cursor_position": 18,
    "language": "python"
})

if response.status_code == 200:
    data = response.json()
    for suggestion in data['suggestions']:
        print(suggestion)
```

### JavaScriptå®¢æˆ·ç«¯ç¤ºä¾‹

```javascript
// è°ƒè¯•åˆ†æ
const response = await fetch('http://localhost:8000/code/debug', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
        code: 'function divide(a, b) { return a / b; }',
        file_path: 'utils.js',
        error_message: 'Cannot divide by zero',
        language: 'javascript'
    })
});

const data = await response.json();
console.log(data.analysis);
```

## éƒ¨ç½²æŒ‡å—

### å¿«é€Ÿéƒ¨ç½²

```bash
# 1. å…‹éš†é¡¹ç›®
git clone <repository-url>
cd ide-python-proxy

# 2. è¿è¡Œéƒ¨ç½²è„šæœ¬
./scripts/deploy.sh

# 3. å¯åŠ¨æœåŠ¡
./scripts/start.sh
```

### æ‰‹åŠ¨éƒ¨ç½²

```bash
# 1. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv venv
source venv/bin/activate

# 2. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 3. é…ç½®ç¯å¢ƒå˜é‡
cp .env.example .env
# ç¼–è¾‘ .env æ–‡ä»¶

# 4. å¯åŠ¨æœåŠ¡
python -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **LLMé…ç½®**: ä½¿ç”¨æœ¬åœ°é«˜æ€§èƒ½LLMæ¨¡å‹
2. **ç¼“å­˜ç­–ç•¥**: å¯ç”¨åµŒå…¥å‘é‡ç¼“å­˜
3. **å¹¶å‘å¤„ç†**: åˆ©ç”¨å¼‚æ­¥å¤„ç†æé«˜å¹¶å‘æ€§èƒ½
4. **èµ„æºé™åˆ¶**: åˆç†è®¾ç½®ä¸Šä¸‹æ–‡é•¿åº¦å’Œåˆ†å—å¤§å°

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **LLMæœåŠ¡è¿æ¥å¤±è´¥**
   - æ£€æŸ¥Ollamaæ˜¯å¦å®‰è£…å’Œè¿è¡Œ
   - ç¡®è®¤æ¨¡å‹æ˜¯å¦å·²ä¸‹è½½

2. **å†…å­˜ä½¿ç”¨è¿‡é«˜**
   - å‡å°‘max_context_length
   - è°ƒæ•´chunk_overlap_ratio

3. **å“åº”é€Ÿåº¦æ…¢**
   - ä½¿ç”¨æ›´å¿«çš„LLMæ¨¡å‹
   - å¯ç”¨åµŒå…¥ç¼“å­˜
   - å‡å°‘max_chunks_per_request

### æ—¥å¿—æŸ¥çœ‹

```bash
# æŸ¥çœ‹åº”ç”¨æ—¥å¿—
tail -f logs/app.log

# æŸ¥çœ‹Ollamaæ—¥å¿—
journalctl -u ollama -f
```